{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Garbage type detection with computer vision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will show you have you can use Computer Vision (CV) to identify the type of waste (i.e plastic, glass, metal, etc) visible in an image.\n",
    "\n",
    "As CV model, we use a Convolutional Neural Network (CNN) architecture which is currently the state-of-the-art architecture CV tasks (i.e. classification, segmentatino, object detectin, etc). The architecture is implemented with the Deep Learning (DL) library PyTorch.\n",
    "\n",
    "We use the [Garbage Classification Dataset](https://www.kaggle.com/asdasdasasdas/garbage-classification)  to train our model. The dataset is composed 2527 images of 6 classes: \n",
    "1. cardboard (403)\n",
    "2. glass (501)\n",
    "3. metal (410)\n",
    "4. paper(594)\n",
    "5. plastic (482)\n",
    "6. trash (137)\n",
    "\n",
    "Figures 1 to 3 show examples of garbadge images from the dataset.\n",
    "<figure>\n",
    "    <img src='html_images/cardboard36.jpg' alt='Fig.1: cardboard' />\n",
    "    <figcaption>Fig.1: cardboard</figcaption>\n",
    "</figure>\n",
    "<figure>\n",
    "    <img src='html_images/plastic11.jpg' alt='Fig.2: plastic' />\n",
    "    <figcaption>Fig.2: plastic</figcaption>\n",
    "</figure>\n",
    "<figure>\n",
    "    <img src='html_images/trash134.jpg' alt='Fig.3: trash' />\n",
    "    <figcaption>Fig.3: trash</figcaption>\n",
    "</figure>\n",
    "\n",
    "As we can see, the dataset is relatively balanced, without any classes below 10% of the total dataset size. Nevertheless, the total number of images (2527) is too small to properly train a CV model from scratch. Therefore, we will use the _transfer learning_ approach, also known as _fine tunning_ approach, where we use a base model already trained on a much larger, but different, dataset and use our samll garbage dataset for an extra training step. \n",
    "\n",
    "As base model for you architecture, we use [RestNet18](https://arxiv.org/abs/1512.03385), a medium size CNN composed of 18 convolutional layers. Desipte being smaller and less perfromant than larger CNN models, ResNet18 offers excellent accuracy on the garbage dataset and can be trained easily on \"small\" accelerated computers, i.e. computers with consumer grade GPU.\n",
    "\n",
    "This notboook is based on the [MNIST Training using PyTorch](https://github.com/aws/amazon-sagemaker-examples/blob/master/sagemaker-python-sdk/pytorch_mnist/pytorch_mnist.ipynb) tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prerequisite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before running this notebook, run the following code in your terminal:\n",
    "```\n",
    "$ pip install -r requirements.txt\n",
    "```\n",
    "Or if you run this notebook in [Amazon SageMaker Notebook](https://docs.aws.amazon.com/sagemaker/latest/dg/nbi.html) or [Amazon SageMaker Studio](https://aws.amazon.com/sagemaker/studio/), simply select the GPU optimized PyTorch kernel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from random import random\n",
    "import shutil\n",
    "\n",
    "from typing import List, Dict\n",
    "\n",
    "def copy_file(source_directory: Path, destination_directory: Path, filename: str):\n",
    "    '''\n",
    "    Copy a file from a source directory to a target directory. If the target file already \n",
    "    exists, the target is overwritten.\n",
    "    '''\n",
    "    destination_directory.mkdir(parents=True, exist_ok=True)\n",
    "    shutil.copy(source_directory/filename, destination_directory/filename)\n",
    "\n",
    "def organize_dataset(root_folder: str, valid_probability: float=0.1):\n",
    "    '''\n",
    "    Organize the dataset into a training set and a test set.\n",
    "    '''\n",
    "    for root, dirs, files in os.walk(root_folder/'original'):\n",
    "        path = root.split(os.sep)\n",
    "        if len(path)<3:\n",
    "            continue\n",
    "\n",
    "        label = path[2]\n",
    "        for file in files:\n",
    "            channel = Path('train') if random()>valid_probability else Path('test')\n",
    "            source_directory = root_folder/'original'/label\n",
    "            destination_directory = root_folder/channel/label\n",
    "            copy_file(source_directory, destination_directory, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we download the dataset from Amazon S3 and store it locally. Then we split it into a training set and a test set. Once the split done, we upload the split dataset to Amazon S3. The S3 location will be used in the Amazon SageMaker training script as data source for the training step. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "root = Path('data')\n",
    "root.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "\n",
    "if not (root/'original.zip').exists():\n",
    "    print('Downloading dataset')\n",
    "    !aws s3 cp s3://ch-workshop/data/original.zip data/original.zip\n",
    "\n",
    "if not (root/'original').exists():\n",
    "    print(\"Unzipping dataset\")\n",
    "\n",
    "    with zipfile.ZipFile(root/'original.zip', 'r') as zip_ref:\n",
    "        zip_ref.extractall(root)\n",
    "\n",
    "if not (root/'train').exists() and not (root/'test').exists():\n",
    "    print(\"Creating train/test structure\")\n",
    "    organize_dataset(root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "bucket = 'ch-workshop'\n",
    "train_prefix = 'data/train'\n",
    "test_prefix = 'data/test'\n",
    "\n",
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train input spec (in this case, just an S3 path): s3://ch-workshop/data/train\n",
      "train input spec (in this case, just an S3 path): s3://ch-workshop/data/test\n"
     ]
    }
   ],
   "source": [
    "train_inputs = sagemaker_session.upload_data(path='data/train', bucket=bucket, key_prefix=train_prefix)\n",
    "print('train input spec (in this case, just an S3 path): {}'.format(train_inputs))\n",
    "\n",
    "test_inputs = sagemaker_session.upload_data(path='data/test', bucket=bucket, key_prefix=test_prefix)\n",
    "print('train input spec (in this case, just an S3 path): {}'.format(test_inputs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a model with Amazon SageMaker Training\n",
    "\n",
    "Training a modern Deep Neural Network (DNN), such as a CNN, requires large computers, accelerated by dedicated GPU. These GPU, such as the Nvidia V100, cost more than 10'000 USD a piece, and several GPU's are generally required to train large model from scratch. In our case, we use _transfer learning_ to reduce computational time and power, but we still need a large GPU to fine-tune our model in an acceptable timeframe (i.e. a few minutes). Without GPU, the training would last several hours, maybe days depending on the CPU power.\n",
    "\n",
    "Such Computational requirement can be a major issue for businesses and academics. To solve this issue, we will use Amazon SageMaker Training. Amazon SageMaker Training provides and manages the infrastructure to train machine learning models. SageMaker Training can operate in four different modes, depending on your requirements and the problem at hand:\n",
    "1. `SageMaker built-in algorithms`: everything is managed by Sagemaker, you only bring your data\n",
    "2. `Sagemaker framework`: you bring the training script and your data, SageMaker takes care of the rest.\n",
    "3. `SageMaker BYO algorithm and framework`: you bring the training script, the libraries used in the training (via a Docker container) and the data. SageMaker takes care of the rest.\n",
    "4. `AWS Marketplace algorithm`: very similar to no 3, but an external vendor provides the training script and the libraries. You bring only the data. From the user perspective, this is very similar to `SageMaker built-in algorithms`. \n",
    "\n",
    "<figure>\n",
    "    <img src='html_images/sagemaker_training_modes.png' alt='Fig.4' />\n",
    "    <figcaption>Fig.4: SageMaker Training: available training modes and their implication</figcaption>\n",
    "</figure>\n",
    "Under the hood, SageMaker Trainging perform the training steps within a Docker container. \n",
    "\n",
    "## An overview of Docker\n",
    "\n",
    "If you're familiar with Docker already, you can skip ahead to the next section.\n",
    "\n",
    "For many data scientists, Docker containers are a new technology. But they are not difficult and can significantly simply the deployment of your software packages.\n",
    "\n",
    "Docker provides a simple way to package arbitrary code into an image that is totally self-contained. Once you have an image, you can use Docker to run a container based on that image. Running a container is just like running a program on the machine except that the container creates a fully self-contained environment for the program to run. Containers are isolated from each other and from the host environment, so the way your program is set up is the way it runs, no matter where you run it.\n",
    "\n",
    "Docker is more powerful than environment managers like conda or virtualenv because (a) it is completely language independent and (b) it comprises your whole operating environment, including startup commands, and environment variable.\n",
    "\n",
    "A Docker container is like a virtual machine, but it is much lighter weight. For example, a program running in a container can start in less than a second and many containers can run simultaneously on the same physical or virtual machine instance.\n",
    "\n",
    "Amazon SageMaker Training invokes a Docker for in a specific way. The following section outline what a training code/script needs to do to work within the SageMaker environment.\n",
    "\n",
    "\n",
    "## The training script\n",
    "\n",
    "For our case, we will use the `Sagemaker framework` mode as it is flexible while removeing infrastructure maintenance from the data scientist. For the `Sagemaker framework` mode, we only bring the training code via a regular python script. During execution in the SageMaker Docker container, the script need to be aware of the following folder structure at runtime:\n",
    "```\n",
    "    /opt/ml\n",
    "    |-- input\n",
    "    |   |-- config\n",
    "    |   |   |-- hyperparameters.json\n",
    "    |   |    -- resourceConfig.json\n",
    "    |    -- data\n",
    "    |        -- <channel_name>\n",
    "    |            -- <input data>\n",
    "    |-- model\n",
    "    |   -- <model files>\n",
    "     -- output\n",
    "        -- failure\n",
    "``` \n",
    "\n",
    "**The input**\n",
    "    \n",
    "* `/opt/ml/input/config` contains information to control how your program runs. hyperparameters.json is a JSON-formatted dictionary of hyperparameter names to values. These values are always strings, so you may need to convert them. resourceConfig.json is a JSON formatted file that describes the network layout used for distributed training.\n",
    "* `/opt/ml/input/data/<channel_name>` (for File mode) contains the input data for that channel. The channels are created based on the call to CreateTrainingJob, but it's generally important that channels match algorithm expectations. The files for each channel are copied from S3 to this directory, preserving the tree structure indicated by the S3 key structure.\n",
    "* `/opt/ml/input/data/<channel_name>_<epoch_number>` (for Pipe mode) is the pipe for a given epoch. Epochs start at zero and go up by one each time you read them. There is no limit to the number of epochs that you can run, but you must close each pipe before reading the next epoch.\n",
    "    \n",
    "**The output**\n",
    "\n",
    "* `/opt/ml/model` is the directory where you write the model that your algorithm generates. Your model can be in any format that you want. It can be a single file or a whole directory tree. SageMaker packages any files in this directory into a compressed tar archive file. This file is made available at the S3 location returned to the DescribeTrainingJob result.\n",
    "* `/opt/ml/output` is a directory where the algorithm can write a file failure that describes why the job failed. The contents of this file are returned to the FailureReason field of the DescribeTrainingJob result. For jobs that succeed, there is no reason to write this file as it is ignored.\n",
    "\n",
    "**The envirnoment variables**\n",
    "\n",
    "Amazon SageMaker injects several useful environment variables in the runtime used by the training script. A list of these variable can be found [here](https://github.com/aws/sagemaker-training-toolkit/blob/master/ENVIRONMENT_VARIABLES.md). Below are listed the most commonly used SageMaker Training environment variables:\n",
    "* `SM_MODEL_DIR`: by default, this is the folder `/opt/ml/model` mentioned above. This is where all the trained artefacts should be saved.\n",
    "* `SM_CHANNEL_<CHANNEL>`: the data channel. The channel names are defined in the `fit` method used to start the training (see a few cell below). e.g. a data scientist might use three data channels for his train: _training_, _val_ and _finaleval_. The environement variables will be `SM_CHANNEL_TRAINING`, `SM_CHANNEL_VAL` and `SM_CHANNEL_FINALEVAL`.\n",
    "\n",
    "**The script**\n",
    "\n",
    "The training script is available in `train.py`. The code should be familiar if you already used PyTorch. The only parts specific for execution in the SageMaker Training environement are the last lines in the function `parse_arguments()`:\n",
    "```python\n",
    "def parse_arguments():\n",
    "    \"\"\"\n",
    "    Parse the script input argument and some environment variables provided at runtime by \n",
    "    Amazon SageMaker Training\n",
    "    \"\"\"\n",
    "    parser = argparse.ArgumentParser()\n",
    "    \n",
    "    # ...\n",
    "    # some classic arguments used in training, such as the number of epoch, the learning rate, etc.\n",
    "    # ...\n",
    "    \n",
    "    # Container environment\n",
    "    parser.add_argument(\"--hosts\", type=list, default=json.loads(os.environ[\"SM_HOSTS\"]))\n",
    "    parser.add_argument(\"--current-host\", type=str, default=os.environ[\"SM_CURRENT_HOST\"])\n",
    "    parser.add_argument(\"--model-dir\", type=str, default=os.environ[\"SM_MODEL_DIR\"])\n",
    "    parser.add_argument(\"--training-dir\", type=str, default=os.environ[\"SM_CHANNEL_TRAINING\"])\n",
    "    parser.add_argument(\"--testing-dir\", type=str, default=os.environ[\"SM_CHANNEL_TESTING\"])\n",
    "    parser.add_argument(\"--num-gpus\", type=int, default=os.environ[\"SM_NUM_GPUS\"])\n",
    "    \n",
    "    # ...\n",
    "```\n",
    "Several environment variables are read in the code snippet above, with the data channels amoung the most important. The script expects two channel: _training_ and _testing_. Let's keep these in mind."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "estimator = PyTorch(entry_point='train.py',\n",
    "                    role=role,\n",
    "                    py_version='py3',\n",
    "                    framework_version='1.8.0',\n",
    "                    instance_count=2,\n",
    "                    instance_type='ml.p3.2xlarge',\n",
    "                    hyperparameters={\n",
    "                        'epochs': 100,\n",
    "                        'backend': 'gloo',\n",
    "                        # 'lr': 1e-4,\n",
    "                        # 'batch_size': 64\n",
    "                    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell above, we created an _PyTorch Estimator_ object. This object holds all the information required for the training, such as the hyperparameters which are passed to the training script as input arguments and processed in the function `parse_arguments()` in the training script.\n",
    "\n",
    "We are now ready to train the model with the `fit` method. The data channel _training_ and _testing_ are defined here. These must match the channel names used in the training script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-28 15:52:15 Starting - Starting the training job.."
     ]
    }
   ],
   "source": [
    "estimator.fit({'training': train_inputs, 'testing': test_inputs})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy and test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = estimator.deploy(initial_instance_count=1, instance_type='ml.m4.xlarge')\n",
    "\n",
    "# from sagemaker.predictor import Predictor\n",
    "# from sagemaker.serializers import NumpySerializer\n",
    "# from sagemaker.deserializers import NumpyDeserializer\n",
    "\n",
    "# predictor = Predictor(endpoint_name='pytorch-training-2021-08-03-11-08-41-872', serializer=NumpySerializer(), deserializer=NumpyDeserializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms, datasets\n",
    "import torch\n",
    "\n",
    "test_transforms = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.6405, 0.6067, 0.5659], [0.2144, 0.2134, 0.2338])\n",
    "    ])\n",
    "\n",
    "test_dataset = datasets.ImageFolder(root/'test', transform=test_transforms)\n",
    "\n",
    "test_dataloader = torch.utils.data.DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=8,\n",
    "        shuffle=True,\n",
    ")\n",
    "\n",
    "batch = next(iter(test_dataloader))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = predictor.predict(batch.numpy())\n",
    "classes = [test_dataset.classes[i] for i in response.argmax(axis=1)]\n",
    "print(f\"Raw prediction result: {response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "\n",
    "mean = torch.tensor([0.6405, 0.6067, 0.5659])\n",
    "stdev = torch.tensor([0.2144, 0.2134, 0.2338])\n",
    "\n",
    "def imshow(axis, inp, pred):\n",
    "    inp = inp.permute(1,2,0)\n",
    "    inp = inp * stdev + mean\n",
    "    axis.imshow(inp)\n",
    "    axis.get_xaxis().set_visible(False)\n",
    "    axis.get_yaxis().set_visible(False)\n",
    "    axis.set_title(pred)\n",
    "\n",
    "fig = plt.figure(1, figsize=(30, 10))\n",
    "grid = ImageGrid(fig, 111, nrows_ncols=(2, 4), axes_pad=0.5)\n",
    "\n",
    "for img, ax, pred in zip(batch, grid, classes):\n",
    "    imshow(ax, img, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_session.delete_endpoint(\n",
    "    endpoint_name = predictor.endpoint_name\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.g4dn.xlarge",
  "kernelspec": {
   "display_name": "Python 3 (PyTorch 1.6 Python 3.6 GPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:eu-west-1:470317259841:image/pytorch-1.6-gpu-py36-cu110-ubuntu18.04-v3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
